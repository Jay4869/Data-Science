{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process(file):\n",
    "    \n",
    "#     temp = pd.read_csv(file)\n",
    "#     temp = temp[temp['Country/Region'] == 'US'] if 'Country/Region' in temp.columns else temp[temp['Country_Region'] == 'US']\n",
    "    \n",
    "#     if 'Admin2' in temp.columns:\n",
    "#         temp['County'] = temp.Admin2\n",
    "#         temp['State'] = temp.Province_State\n",
    "#     elif temp['Province/State'].str.contains(',').any() and (temp['Province/State'] != 'Virgin Islands, U.S.').all():\n",
    "#         x = temp['Province/State'].str.replace(' (From Diamond Princess)','', regex=False).replace('Unassigned Location','', regex=False).str.split(', ')\n",
    "#         temp['County'] = x.map(lambda x: x[0])\n",
    "#         temp['State'] = x.map(lambda x: x[-1])\n",
    "#     else:\n",
    "#         temp['County'] = ''\n",
    "#         temp['State'] = temp['Province/State'].str.replace(' (From Diamond Princess)','', regex=False).str.replace('Unassigned Location','', regex=False)\n",
    "    \n",
    "#     temp['County'] = temp['County'].str.replace(' County', '', regex=False)\n",
    "#     temp['Date'] = pd.to_datetime(file[-14:-4]).strftime('%Y-%m-%d')\n",
    "    \n",
    "#     temp['Lat'] = temp['Latitude'] if 'Latitude' in temp.columns else np.nan\n",
    "    \n",
    "#     if 'Longitude' in temp.columns:\n",
    "#         temp['Long'] = temp['Longitude']\n",
    "#     elif 'Long_' in temp.columns:\n",
    "#         temp['Long'] = temp['Long_']\n",
    "#     else:\n",
    "#         temp['Long'] = np.nan\n",
    "    \n",
    "#     temp['Deaths'] = temp.Deaths\n",
    "#     temp['Recovered'] = temp.Recovered if 'Recovered' in temp.columns else 0\n",
    "#     temp['Active'] = temp['Active'] if 'Active' in temp.columns else 0\n",
    "#     temp['FIPS'] = temp['FIPS'] if 'FIPS' in temp.columns else np.nan\n",
    "    \n",
    "#     temp = temp[['FIPS', 'County', 'State', 'Date', 'Lat', 'Long', 'Confirmed', 'Deaths', 'Recovered', 'Active']]        \n",
    "\n",
    "#     return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path = '../../../COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "\n",
    "# if not os.path.exists('covid_19_US.csv'):\n",
    "#     files = [i for i in os.listdir(path) if 'csv' in i]\n",
    "#     data = pd.DataFrame([])\n",
    "\n",
    "#     for i in files:\n",
    "#         print('loading {}'.format(i))\n",
    "#         temp = process(path + i)\n",
    "#         data = pd.concat([data, temp], ignore_index=True)\n",
    "\n",
    "#     print(data.shape)\n",
    "# else:\n",
    "#     data = pd.read_csv('covid_19_US.csv').drop('Unnamed: 0', axis=1)\n",
    "#     files = [i for i in os.listdir(path) if i[:5] > max(data.Date)[-5:] and '2020' in i]\n",
    "    \n",
    "#     for i in files:\n",
    "#         print('loading {}'.format(i))\n",
    "\n",
    "#         try:\n",
    "#             temp = process(path + i)\n",
    "#         except ValueError:\n",
    "#             print('New file has different format.')\n",
    "        \n",
    "#         assert(data.shape[1] == 10)\n",
    "#         data = pd.concat([data, temp], ignore_index=True)\n",
    "\n",
    "# print('There are total {} records.'.format(data.shape[0]))\n",
    "\n",
    "# data.sort_values('Date').to_csv('covid_19_US.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23820</th>\n",
       "      <td>38065.0</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-101.340616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21378</th>\n",
       "      <td>47107.0</td>\n",
       "      <td>McMinn</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.615207</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>35047.0</td>\n",
       "      <td>San Miguel</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-104.816356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44376</th>\n",
       "      <td>51740.0</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-76.359716</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Riverside County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>33.9533</td>\n",
       "      <td>-117.396100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29608</th>\n",
       "      <td>38043.0</td>\n",
       "      <td>Kidder</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99.775079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16590</th>\n",
       "      <td>16011.0</td>\n",
       "      <td>Bingham</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-112.397844</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>38003.0</td>\n",
       "      <td>Barnes</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-98.066060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>47153.0</td>\n",
       "      <td>Sequatchie</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85.410221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>48027.0</td>\n",
       "      <td>Bell</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.478503</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FIPS            County         State        Date      Lat  \\\n",
       "23820  38065.0            Oliver  North Dakota  2020-03-29      NaN   \n",
       "21378  47107.0            McMinn     Tennessee  2020-03-28      NaN   \n",
       "31099  35047.0        San Miguel    New Mexico  2020-03-31      NaN   \n",
       "44376  51740.0        Portsmouth      Virginia  2020-04-06      NaN   \n",
       "831        0.0  Riverside County            CA  2020-03-08  33.9533   \n",
       "29608  38043.0            Kidder  North Dakota  2020-03-30      NaN   \n",
       "16590  16011.0           Bingham         Idaho  2020-03-26      NaN   \n",
       "2853   38003.0            Barnes  North Dakota  2020-03-22      NaN   \n",
       "5996   47153.0        Sequatchie     Tennessee  2020-03-23      NaN   \n",
       "6799   48027.0              Bell         Texas  2020-03-23      NaN   \n",
       "\n",
       "             Long  Confirmed  Deaths  Recovered  Active  \n",
       "23820 -101.340616        0.0     0.0        0.0       0  \n",
       "21378  -84.615207        3.0     0.0        0.0       0  \n",
       "31099 -104.816356        1.0     0.0        0.0       0  \n",
       "44376  -76.359716       27.0     0.0        0.0       0  \n",
       "831   -117.396100        1.0     0.0        0.0       0  \n",
       "29608  -99.775079        0.0     0.0        0.0       0  \n",
       "16590 -112.397844        2.0     0.0        0.0       0  \n",
       "2853   -98.066060        0.0     0.0        0.0       0  \n",
       "5996   -85.410221        0.0     0.0        0.0       0  \n",
       "6799   -97.478503       16.0     0.0        0.0       0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETL(file):\n",
    "\n",
    "    # loading COVID-19 data and zipcode\n",
    "    print('Processing {}'.format(file[-14:]))\n",
    "    data = pd.read_csv(file)\n",
    "    zipinfo = pd.read_csv('uszips.csv')[['county_fips', 'county_name', 'state_name', 'lat', 'lng']].drop_duplicates()\n",
    "    zipinfo = zipinfo.groupby(['county_fips', 'county_name', 'state_name']).agg('mean').reset_index()\n",
    "\n",
    "    # extract US records and features\n",
    "    data = data.loc[data.Country_Region == 'US', ['FIPS', 'Admin2', 'Province_State', 'Confirmed', 'Deaths']]\n",
    "\n",
    "    # rename features\n",
    "    data.columns = ['FIPS', 'County', 'State', 'Confirmed', 'Deaths']\n",
    "\n",
    "    # remove 'City' in the County columns to match zipcode table\n",
    "    data.County = data.County.str.replace(' City', '', regex=False)\n",
    "\n",
    "    # final output features\n",
    "    feature = ['FIPS', 'County', 'State', 'lat', 'lng', 'Confirmed', 'Deaths']\n",
    "\n",
    "    # extract non-missing records\n",
    "    x = pd.merge(data, zipinfo, left_on = ['FIPS', 'County', 'State'],\n",
    "                 right_on = ['county_fips', 'county_name', 'state_name'], how = 'inner')[feature]\n",
    "\n",
    "    # correct wrong FIPS and fill in missing\n",
    "    y = data[~data.FIPS.isin(x.FIPS)]\n",
    "    z = pd.merge(y, zipinfo, left_on = ['County', 'State'], right_on = ['county_name', 'state_name'], how = 'inner')\n",
    "    z.FIPS = z.county_fips\n",
    "    z = z[feature]\n",
    "\n",
    "    # merge two tables\n",
    "    data = pd.concat([x, z], ignore_index = True).groupby(['FIPS', 'County', 'State']).agg('sum').reset_index()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def increment(x, y):\n",
    "    temp = pd.merge(x, y[['FIPS', 'County', 'State', 'Confirmed', 'Deaths']],\n",
    "                    on=['FIPS', 'County', 'State'], how='left')\n",
    "    temp.Confirmed_y.fillna(0, inplace=True)\n",
    "    temp.Deaths_y.fillna(0, inplace=True)\n",
    "    temp['Confirmed_new'] = (temp.Confirmed_x - temp.Confirmed_y).astype(int)\n",
    "    temp['Deaths_new'] = (temp.Deaths_x - temp.Deaths_y).astype(int)\n",
    "    temp['Confirmed'] = temp.Confirmed_x\n",
    "    temp['Deaths'] = temp.Deaths_x\n",
    "    temp = temp[['FIPS', 'County', 'State', 'lat', 'lng', 'Confirmed', 'Confirmed_new', 'Deaths', 'Deaths_new']]\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 04-10-2020.csv\n"
     ]
    }
   ],
   "source": [
    "path = '../../../COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "file = path + '04-10-2020.csv'\n",
    "data10 = ETL(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 04-11-2020.csv\n"
     ]
    }
   ],
   "source": [
    "path = '../../../COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "file = path + '04-11-2020.csv'\n",
    "data11 = ETL(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2632, 9)"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = increment(data11,data10)\n",
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv('us_county.csv')[['fips', 'population']]\n",
    "temp = pd.merge(diff, pop, left_on = 'FIPS', right_on = 'fips', how = 'left').drop('fips', axis = 1)\n",
    "temp.eval(\"Confirmed_rate = Confirmed / population\", inplace =True)\n",
    "temp.eval(\"Deaths_rate = Deaths / Confirmed\", inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Confirmed_new</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Deaths_new</th>\n",
       "      <th>population</th>\n",
       "      <th>Confirmed_rate</th>\n",
       "      <th>Deaths_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>36061.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.762071</td>\n",
       "      <td>-73.976000</td>\n",
       "      <td>98308</td>\n",
       "      <td>5924.0</td>\n",
       "      <td>6367</td>\n",
       "      <td>547.0</td>\n",
       "      <td>1632480</td>\n",
       "      <td>0.060220</td>\n",
       "      <td>0.064766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>36087.0</td>\n",
       "      <td>Rockland</td>\n",
       "      <td>New York</td>\n",
       "      <td>41.128793</td>\n",
       "      <td>-74.003296</td>\n",
       "      <td>7477</td>\n",
       "      <td>355.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>323686</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.026749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16013.0</td>\n",
       "      <td>Blaine</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>43.537407</td>\n",
       "      <td>-114.256719</td>\n",
       "      <td>452</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21994</td>\n",
       "      <td>0.020551</td>\n",
       "      <td>0.011062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>36119.0</td>\n",
       "      <td>Westchester</td>\n",
       "      <td>New York</td>\n",
       "      <td>41.114868</td>\n",
       "      <td>-73.782423</td>\n",
       "      <td>18729</td>\n",
       "      <td>652.0</td>\n",
       "      <td>461</td>\n",
       "      <td>72.0</td>\n",
       "      <td>968815</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>0.024614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>36059.0</td>\n",
       "      <td>Nassau</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.730876</td>\n",
       "      <td>-73.614145</td>\n",
       "      <td>22584</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>792</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1356564</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>0.035069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FIPS       County     State        lat         lng  Confirmed  \\\n",
       "1547  36061.0     New York  New York  40.762071  -73.976000      98308   \n",
       "1558  36087.0     Rockland  New York  41.128793  -74.003296       7477   \n",
       "513   16013.0       Blaine     Idaho  43.537407 -114.256719        452   \n",
       "1574  36119.0  Westchester  New York  41.114868  -73.782423      18729   \n",
       "1546  36059.0       Nassau  New York  40.730876  -73.614145      22584   \n",
       "\n",
       "      Confirmed_new  Deaths  Deaths_new  population  Confirmed_rate  \\\n",
       "1547         5924.0    6367       547.0     1632480        0.060220   \n",
       "1558          355.0     200         0.0      323686        0.023100   \n",
       "513             6.0       5         0.0       21994        0.020551   \n",
       "1574          652.0     461        72.0      968815        0.019332   \n",
       "1546         1072.0     792        69.0     1356564        0.016648   \n",
       "\n",
       "      Deaths_rate  \n",
       "1547     0.064766  \n",
       "1558     0.026749  \n",
       "513      0.011062  \n",
       "1574     0.024614  \n",
       "1546     0.035069  "
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.sort_values('Confirmed_rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 04-10-2020.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "489630"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../../COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "file = path + '04-10-2020.csv'\n",
    "data10 = ETL(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>32.580766</td>\n",
       "      <td>-86.615497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>30.594986</td>\n",
       "      <td>-87.724403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31.780406</td>\n",
       "      <td>-85.435020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33.020930</td>\n",
       "      <td>-87.090535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33.924849</td>\n",
       "      <td>-86.599899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county_fips county_name state_name        lat        lng\n",
       "0         1001     Autauga    Alabama  32.580766 -86.615497\n",
       "1         1003     Baldwin    Alabama  30.594986 -87.724403\n",
       "2         1005     Barbour    Alabama  31.780406 -85.435020\n",
       "3         1007        Bibb    Alabama  33.020930 -87.090535\n",
       "4         1009      Blount    Alabama  33.924849 -86.599899"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv('./uszips.csv')[['county_fips', 'county_name', 'state_name', 'lat', 'lng']].drop_duplicates()\n",
    "x.groupby(['county_fips', 'county_name', 'state_name']).agg('mean').reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <th>Autauga</th>\n",
       "      <th>Alabama</th>\n",
       "      <td>32.580766</td>\n",
       "      <td>-86.615497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <th>Baldwin</th>\n",
       "      <th>Alabama</th>\n",
       "      <td>30.594986</td>\n",
       "      <td>-87.724403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <th>Barbour</th>\n",
       "      <th>Alabama</th>\n",
       "      <td>31.780406</td>\n",
       "      <td>-85.435020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <th>Bibb</th>\n",
       "      <th>Alabama</th>\n",
       "      <td>33.020930</td>\n",
       "      <td>-87.090535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <th>Blount</th>\n",
       "      <th>Alabama</th>\n",
       "      <td>33.924849</td>\n",
       "      <td>-86.599899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lat        lng\n",
       "county_fips county_name state_name                      \n",
       "1001        Autauga     Alabama     32.580766 -86.615497\n",
       "1003        Baldwin     Alabama     30.594986 -87.724403\n",
       "1005        Barbour     Alabama     31.780406 -85.435020\n",
       "1007        Bibb        Alabama     33.020930 -87.090535\n",
       "1009        Blount      Alabama     33.924849 -86.599899"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./uszips.csv').groupby(['county_fips', 'county_name', 'state_name'])['lat', 'lng'].agg('mean').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
