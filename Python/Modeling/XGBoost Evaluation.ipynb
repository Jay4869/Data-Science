{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xbgoost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler, StandScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, plot_precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c339ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evalution(booster, x, y, best_rounds, prob=False):\n",
    "    \n",
    "    y_pred_prob = booster.predict(x, ntree_limit = best_rounds)\n",
    "    \n",
    "    if prob:\n",
    "        precision, recall, thresholds = precision_recall_curve(y, y_pred_prob)\n",
    "        aucpr = aue(recall, precision)\n",
    "        roc = roc_auc_score(y, y_pred_prob)\n",
    "        i = np.where(np.array(thresholds) >= prob)[0][0]\n",
    "        y_pred = [i if j >= thresholds[i] else 0 for j in y_pred_prob]\n",
    "        accuracy = accuracy_score(y, y_pred, normalize=True)\n",
    "        f1 = f1_score(y, y_pred)\n",
    "        conf = confusion_matrix(y, y_pred)\n",
    "    else:\n",
    "        precision, recall, thresholds = precision_recall_curve(y, y_pred_prob)\n",
    "        aucpr = aue(recall, precision)\n",
    "        roc = roc_auc_score(y, y_pred_prob)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        i = np.argmax(f1)\n",
    "        y_pred = [i if j >= thresholds[i] else 0 for j in y_pred_prob]\n",
    "        accuracy = accuracy_score(y, y_pred, normalize=True)\n",
    "        conf = confusion_matrix(y, y_pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8fa25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_visualization(booster, output):\n",
    "    \n",
    "    temp = booster.get_score(importance_type = 'total_gain')\n",
    "    features = list(temp.keys())\n",
    "    values = list(temp.values())\n",
    "    \n",
    "    feature_importance = pd.DataFrame(zip(features, values), columns = ['Features', 'Scores']).sort_values(by = 'Scores', ascending=False)\n",
    "    feature_importance['Scores_norm'] = feature_importance.Scores / feature_importance.Scores.sum()\n",
    "    feature_importance.to_csv(output + '.csv', index = False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.barplot(x = 'Scores_norm', y = 'Features', data = feature_importance.head(30))\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.savefig(output + '.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
